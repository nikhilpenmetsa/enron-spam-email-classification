{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-26 23:26:48 Starting - Starting the training job...ProfilerReport-1666826808: InProgress\n",
      "...\n",
      "2022-10-26 23:27:32 Starting - Preparing the instances for training............\n",
      "2022-10-26 23:29:32 Downloading - Downloading input data...\n",
      "2022-10-26 23:30:13 Training - Downloading the training image..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[10/26/2022 23:30:28 WARNING 140130880444224] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[10/26/2022 23:30:28 WARNING 140130880444224] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[10/26/2022 23:30:28 INFO 140130880444224] nvidia-smi took: 0.07566452026367188 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[10/26/2022 23:30:28 INFO 140130880444224] Running single machine CPU BlazingText training using supervised mode.\u001b[0m\n",
      "\u001b[34mNumber of CPU sockets found in instance is  1\u001b[0m\n",
      "\u001b[34m[10/26/2022 23:30:28 INFO 140130880444224] 109 files found in train channel. Using /opt/ml/input/data/train/train.csv for training...\u001b[0m\n",
      "\u001b[34m[10/26/2022 23:30:28 INFO 140130880444224] Processing /opt/ml/input/data/train/train.csv . File size: 25.89203453063965 MB\u001b[0m\n",
      "\u001b[34m[10/26/2022 23:30:28 INFO 140130880444224] Processing /opt/ml/input/data/validation/validation.csv . File size: 2.9755048751831055 MB\u001b[0m\n",
      "\u001b[34mRead 4M words\u001b[0m\n",
      "\u001b[34mNumber of words:  68937\u001b[0m\n",
      "\u001b[34mLoading validation data from /opt/ml/input/data/validation/validation.csv\u001b[0m\n",
      "\u001b[34mLoaded validation data.\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0488  Progress: 2.30%  Million Words/sec: 6.28 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 1\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 2\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0463  Progress: 7.34%  Million Words/sec: 6.53 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 3\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 4\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0438  Progress: 12.39%  Million Words/sec: 6.58 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 5\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 6\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0412  Progress: 17.52%  Million Words/sec: 6.63 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 7\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 8\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0386  Progress: 22.84%  Million Words/sec: 6.71 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 9\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 10\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 11\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0359  Progress: 28.27%  Million Words/sec: 6.97 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 12\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 13\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0331  Progress: 33.73%  Million Words/sec: 7.19 #####\u001b[0m\n",
      "\n",
      "2022-10-26 23:30:33 Training - Training image download completed. Training in progress.\u001b[34m-------------- End of epoch: 14\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 15\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0304  Progress: 39.19%  Million Words/sec: 7.34 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 16\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 17\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0277  Progress: 44.53%  Million Words/sec: 7.44 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 18\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 19\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0251  Progress: 49.82%  Million Words/sec: 7.52 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 20\u001b[0m\n",
      "\u001b[34mUsing 4 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.988731\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 21\u001b[0m\n",
      "\u001b[34mUsing 4 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.98962\u001b[0m\n",
      "\u001b[34mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0224  Progress: 55.29%  Million Words/sec: 7.27 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 22\u001b[0m\n",
      "\u001b[34mUsing 4 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.988731\u001b[0m\n",
      "\u001b[34mValidation accuracy has not improved for last 1 epochs.\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 23\u001b[0m\n",
      "\u001b[34mUsing 4 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.98962\u001b[0m\n",
      "\u001b[34mValidation accuracy has not improved for last 2 epochs.\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0198  Progress: 60.44%  Million Words/sec: 7.20 #####\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 24\u001b[0m\n",
      "\u001b[34mUsing 4 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.989027\u001b[0m\n",
      "\u001b[34mValidation accuracy has not improved for last 3 epochs.\u001b[0m\n",
      "\u001b[34m-------------- End of epoch: 25\u001b[0m\n",
      "\u001b[34mUsing 4 threads for prediction!\u001b[0m\n",
      "\u001b[34mValidation accuracy: 0.98962\u001b[0m\n",
      "\u001b[34mValidation accuracy has not improved for last 4 epochs.\u001b[0m\n",
      "\u001b[34mReached patience. Terminating training.\u001b[0m\n",
      "\u001b[34mBest epoch: 21\u001b[0m\n",
      "\u001b[34mBest validation accuracy: 0.98962\u001b[0m\n",
      "\u001b[34m##### Alpha: 0.0000  Progress: 100.00%  Million Words/sec: 11.31 #####\u001b[0m\n",
      "\u001b[34mTraining finished.\u001b[0m\n",
      "\u001b[34mAverage throughput in Million words/sec: 11.31\u001b[0m\n",
      "\u001b[34mTotal training time in seconds: 15.19\u001b[0m\n",
      "\u001b[34m#train_accuracy: 1\u001b[0m\n",
      "\u001b[34mNumber of train examples: 26972\u001b[0m\n",
      "\u001b[34m#validation_accuracy: 0.9896\u001b[0m\n",
      "\u001b[34mNumber of validation examples: 3372\u001b[0m\n",
      "\n",
      "2022-10-26 23:31:13 Uploading - Uploading generated training model\n",
      "2022-10-26 23:31:33 Completed - Training job completed\n",
      "ProfilerReport-1666826808: NoIssuesFound\n",
      "Training seconds: 122\n",
      "Billable seconds: 122\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "\n",
    "proj_bucket = \"nikhil-spam-ham\"\n",
    "\n",
    "container = sagemaker.image_uris.retrieve('blazingtext', boto3.Session().region_name)\n",
    "\n",
    "output_path='s3://{}/{}/output'.format(proj_bucket, \"training_output\")\n",
    "estimator = sagemaker.estimator.Estimator(container,\n",
    "                                    sagemaker.get_execution_role(), \n",
    "                                    instance_count=1, \n",
    "                                    instance_type='ml.m4.xlarge',\n",
    "                                    output_path=output_path,\n",
    "                                    sagemaker_session=sagemaker.Session(),\n",
    "                                    hyperparameters={\n",
    "                                        \"mode\": \"supervised\",\n",
    "                                        \"epochs\": 40,\n",
    "                                        \"min_count\": 2,\n",
    "                                        \"learning_rate\": 0.05,\n",
    "                                        \"vector_dim\": 10,\n",
    "                                        \"early_stopping\": True,\n",
    "                                        \"patience\": 4,\n",
    "                                        \"min_epochs\": 20,\n",
    "                                        \"word_ngrams\": 2,\n",
    "                                    })\n",
    "\n",
    "train_path = f\"s3://{proj_bucket}/train\"\n",
    "validation_path = f\"s3://{proj_bucket}/validation\"\n",
    "\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data=train_path.format(proj_bucket, \"train.csv\"), content_type='csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data=validation_path.format(proj_bucket, \"validation.csv\"), content_type='csv')\n",
    "\n",
    "model = estimator.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1,instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictor name: blazingtext-2022-10-26-23-32-03-964\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predictor name: {predictor.endpoint_name}\")"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
